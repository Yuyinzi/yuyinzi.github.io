---
title: 《Redis设计与实现》读书笔记 第三/四部分
date: 2019-04-15 14:25:56
tags:
- Redis
categories:
- 数据库
---

因为第四部分只挑了感兴趣的部分看，于是将第三第四部分合并起来。主要介绍的有：

- `redis`是如何实现主从一致的
- `redis`的`sentinel`是如何发现下线服务器并进行故障转移的
- `redis`的集群是如何进行数据分片的，什么是`Gossip`协议
- `redis`的发布与订阅功能是如何实现的

<!-- more -->

## 第十五章 复制 

用户可以通过执行`SLAVEOF`命令让一个服务器(从服务器)去复制另一个服务器(主服务器)。复制功能包括同步(`sync`)和命令传播(`command propagate`)：

- 同步用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态；
- 命令传播用户当主服务器**被修改**时，让主从服务器恢复到一致状态。 

针对`2.8`版本以前采用的是旧版复制，具有较大的性能缺陷。 

### 旧版复制 

同步操作是通过由从服务器向主服务器发送`SYNC`命令完成的，主要包括两个部分： 

- 主服务器收到命令后，使用`BGSAVE`生成`RDB`，并且将`RDB`文件发送给从服务器，从服务器载入`RDB`文件； 

- 主服务器将执行`BGSAVE`命令(但没执行完)时保存在缓冲区里的写命令发送给从服务器。 

同步操作完毕之后，需要根据命令传播保持主从数据库的一致。但是如果**在命令传播的过程中**，发生了**主从服务器断线**，从服务器仍然会向主服务器发送`SYNC`命令，即主数据库会重新执行`BGSAVE`生成`RDB`文件，其中包含了断线前已经同步的数据，是没有必要的。 

> `SYNC`命令十分耗费资源，因为在生成`RDB`的过程中，会耗费主服务器大量的`CPU`、内存和磁盘`I/O`资源；在发送`RDB`的过程中，会占用主从服务器大量的带宽；接收到`RDB`文件的从服务器需要载入，此时会发生阻塞。 

### 新版复制 

新版复制主要可以解决旧版复制功能处理断线重复复制的低效问题，它使用`PSYNC`替代`SYNC`，具有完整重同步和部分重同步两种模式： 

- 完整重同步用于初次复制情况，和`SYNC`处理方式一致 

- 部分重同步用于处理断线重复制情况，只需要将从服务器缺少的写命令发送给从服务器即可。 

部分重同步的实现在于，需要记录三个部分： 

- 主从服务器的复制偏移量：主服务器通过比对与重服务器中数据的偏移量是否一致，判断主从服务器是否处于一致状态。 

- 主服务器的复制积压缓冲区：当主从数据库的复制偏移量不一致时，会判断复制积压缓冲区中是否存在偏移量之后的数据(**复制积压区是一个固定长度的先进先出队列**)。如果数据仍然存在，则进行部分重同步操作；否则执行完整重同步操作。由于复制积压区固定长度，所以需要针对网络断线情况以及主服务器接受的命令数来合理调整其大小。 

- 服务器的运行`ID`：从服务器中会保存主服务器的运行`ID`，当断线重连后，从服务器会重新发送该`ID`，如果与主服务器`ID`一致，主服务器可以继续执行部分重同步操作，否则执行完整重同步操作。 

如果是初次复制操作，从服务器会发送`PSYNC ? -1`，否则发送`PSYNC <runid> <offset>`，主服务器会根据情况判断进行完整重同步还是部分重同步操作。 

### 复制的实现 

- 客户端设置主服务器的地址和端口，保存到从服务器的`redisServer`中，只有当保存工作完成之后，复制工作才会真正开始； 

- 从服务器与主服务器之间建立套接字连接，从服务器会为它关联一个专门用于处理复制工作的文件事件处理器，负责接收`RDB`文件，接收传播来的写命令等； 

- 从服务器发送`PING`命令，用来检查套接字的读写状态是否正常以及主服务器是否能够正常处理命令请求(若没有出现`PONG`的回复，则表示异常，需要重新建立套接字)； 

- 身份验证，如果主服务器设置了`requirepass`，服务器也需要设置`masterauth`，要么都不设置，否则都会使得从服务器目前的复制工作终端，并从创建套接字开始重新执行，直到身份验证通过或者从服务器主动放弃复制； 

- 从服务器发送`REPLCONF listening-port <port-number>`，主服务器会将该端口号记录在客户端状态中，主要用于`INFO replication`的打印中； 

- 从服务器发送`PSYNC`执行同步，执行以后**主从服务器互为双方的客户端**，因为主服务器需要将缓冲区/复制积压缓冲区的写命令发送给从服务器。 

- 完成同步之后，进入命令传播阶段。 主服务器只要一直讲命令发送给从服务器，从服务器只要一直接收主服务器的命令，就可以保证主从服务器一致了。

### 心跳检测 

**命令传播**阶段，从服务器默认`1s`的频率向主服务器发送`REPLCONF ACK <replication_offset>`，`replication_offset`是从服务器当前的复制偏移量，有三个用途： 

- 检测主从服务器的网络连接，如果主服务器超过`1s`没有收到从服务器的`ACK`命令(可以通过`INFO replication`的`lag`看到)，说明主从服务器的连接出现了故障。 

- 辅助实现`min-slaves`配置，主服务器可以提供`min-slaves-to-write`(要求写入时的从服务器数量)和`min-slaves-max-lag`(要求写入时的从服务器延迟)，防止在不安全的情况下执行写命令。 

- 检测命令丢失，如果在命令传播中发生了写命令丢失的情况，主服务器仍然可以根据复制偏移量将这些数据重新发送给从服务器(类似`TCP`中的`ack`)。 

> 补发缺失数据操作在主从服务器没有断线的情况下执行，部分重同步操作在断线重连的情况下执行。 

## 第十六章 `Sentinel` 

`Sentinel`(哨兵)系统可以监视任意多个主服务器，以及主服务器下的所有从服务器，并且当主服务器下线时将从服务器升级为新的主服务器，选举局部`Sentinel`领头以及`Sentinel`领头。 

### 本质 

可以使用: 

``` shell
$redis-server /path/to/your/sentinel.conf --sentinel 
```

或者 

``` shell
$redis-sentinel /path/to/your/sentinel.conf 
```

启动一个`sentinel`服务器。 

实际上，它是一个运行在**特殊模式下的`redis`服务器**。但是它不使用数据库，不会载入`RDB`或者`AOF`文件，端口使用`REDIS_SENTINEL_PORT`指定(普通`redis`服务器端口使用`REDIS_SERVERPORT`)，它只支持`PING`/`SENTINEL`/`INFO`/`SUBSCRIBE`/`UNSUBSCRIBE`/`PSUBSCRIBE`和`PUNSUBSCRIBE`七个命令。 

基本数据结构： 

```C 
struct sentinelState{ 
  // 当前纪元，同一纪元下sentinel领头不能发生变化 
  unint64_t current_epoch; 
  // 记录所有被监视的主服务器相关信息 
  dict * masters; 
  ... 
} 
```

`masters`保存了`sentinelRedisInstance`结构，每一个结构代表被`sentinel`监视的`redis`服务器实例(包括主服务器，从服务器，或者是另外的`sentinel`)。它结构体如下： 

```C 
struct sentinelRedisInstance{ 
  // 实例名字/运行id 
  char * name; 
  char * runid; 
  unit64_t config_epoch; 
  // 实例响应超过down_after_period，会判断主观下线 
  mstime_t down_after_period; 
  // 判断实例客观下线需要的投票数量 
  int quorum; 
  dict * slaves; 
  // 所有监视该服务器的sentinel 
  dict * sentinels; 
  ... 
} 
```

当初始化完成之后，`sentinel`将成为主服务器的客户端。它会与主服务器创建`2`个异步网络连接： 

- 命令连接，用于发送命令与接收命令回复。 

- 订阅连接，用于订阅主服务器的`__sentinel__:hello`频道 

### 获取主服务器信息 

`sentinel`默认每`10s`一次向主服务器发送`INFO`，根据回复可以获得： 

- 主服务器本身的运行`id`，以及`role`域记录的服务器角色； 

- 主服务器下所有从服务器的信息，用来更新主服务器`sentinelRedisInstance`中的`slaves`字典 

### 获取从服务器信息 

由上面所说可以发现，`sentinel`可以自动发现从服务器。

当发现主服务器有新的从服务器出现时，`sentinel`不仅会为新的从服务器创建相应的实例结构，还会**创建到从服务器的命令连接和订阅连接**。也是默认每`10s`向从服务器发送`INFO`，获得从服务器的运行`id`，`ip`以及优先级、偏移量、连接状态等(为了方便以后将从服务器升级为主服务器)。 

### 发现/更新`sentinel`信息 

默认情况下，`sentinel`会每隔`2s`向被监视的主/从服务器的`__sentinel__:hello`频道发送消息。对于监视同一个服务器的多个`sentinel`来说，一个`sentinel`发送的信息会被其他`sentinel`接收，用以互相更新`sentinel`之间的认知：当一个`sentinel`接收到其他`sentinel`(源)发送而来的信息时，会在自己的`masters`字典中查找对应的主服务器实例结构，检查其`sentinels`中是否存在源`sentinel`并进行更新(不存在说明源`sentinel`刚开始监视该主服务器，此时需要创建并添加到`sentinels`中)。因此，监视同一个主服务器的多个`sentinel`可以自动发现对方。 

> 监视同一主服务器的`sentinel`之间会创建命令连接，并不会创建订阅连接。订阅连接用来发现新的`sentinel`。 

### 检测主观/客观下线 

默认情况，`sentinel`会以`1s`的频率向其他创建命令连接的实例(主/从服务器)，其他`sentinel`发送`PING`命令判断实例是否在线。 

**主观下线**： 

如果一个实例在`down_after_milliseconds`时间(这个时间也适用于主服务器下所有从服务器，以及监视主服务器的其他`sentinel`。多个`sentinel`设置的时间可以不同，即不同`sentinel`认为同一实例主观下线的标准并不一致)内连续向`sentinel`返回无效回复，`sentinel`对在创建的实例中的`flags`修改为`SRI_S_DOWN`，表示它认为此实例已经进入主观下线。 

**客观下线**： 

当`sentinel`判断主服务器已经主观下线之后，会向其他监视主服务器的`sentinel`询问是否他们也认为主服务器已经下线。当接收到足够数量(`quorum`)的下线判断时，`sentinel`会将从服务器判定为客观下线(不同`sentinel`认为同一实例客观下线的标准也并不一致)。此时`flags`标记为`SRI_O_DOWN`。客观下线条件只适用于主服务器。

按照我的理解，即使当主服务器被认为下线了，实际上仍然有`sentinel`并不觉得它已主观下线。只要半数以上的`sentinel`认为它已经主观下线，那么这个主服务器其实已经没有当主服务器的必要了，于是可以对它进行故障转移。 

### 选举领头`sentinel` 

只要一个`Sentinel`发现某个主服务器进入了客观下线状态，监视这个下线主服务器的各个`sentinel`会进行协商，选举领头`sentinel`，由其对失效的主服务器执行自动故障迁移操作。 

> 每次领头`sentinel`选举，无论成功与否，配置纪元都会自增一次。局部领头(每个`sentinel`都会要求其他`sentinel`将自己设为局部领头，采取先到先得规则)一旦设置，配置纪元里不能再更改。只有获得半数以上的局部领头，才能真正成为真正的领头。 

### 故障转移 (`failover`)

领头`sentinel`需要对已下线的主服务器执行故障转移： 

- 从从服务器中挑选一个转换为主服务器 

- 让已下线主服务器属下的从服务器改为复制新的主服务器 

- 将已下线主服务器设置为新主服务器的从服务器 

> 在升级从服务器时，领头`sentinel`会以`1s`的频率发送`INFO`命令 

当以前的主服务器上线之后，`Leader`会向其发送`SLAVEOF`命令，使其复制新`master`的数据。(因为需要更改实例中的`masterport`之类的参数)

`Sentinel`集群运行过程中故障转移完成，所有`Sentinel`又会恢复平等。`Leader`仅仅是故障转移操作出现的角色。

`Leader`并不会把自己成为`Leader`的消息发给其他`Sentinel`。其他`Sentinel`等待`Leader`从`slave`选出`master`后，检测到新的`master`正常工作后，就会去掉客观下线的标识，从而不需要进入故障转移流程。

## 第十七章 集群

`redis`集群是`redis`提供的分布式方案，通过分片进行数据共享，提供复制和故障转移等功能。

### 节点

一个节点是一个运行在集群模式下的服务器，通过`cluser-enabled`选项进行配置。它与普通服务器的区别包括：

- `serverCron`函数会执行`clusterCron`，执行集群下常规操作
- 集群中需要用到的数据，采用`cluserNode`，`clusterLink`以及`clusterState`来保存。

**`clusterNode`**

每个节点都有自己的`clusterNode`结构来记录自己的状态，包括节点的创建时间，名字，配置纪元`IP`地址和端口号等，还包含了一个`clusterLink`结构的指针，指向`link`：

```C 
struct clusterNode{
  // 记录节点处理哪些槽
  unsigned char slots[16384/8];
  int numslots;
  
  clusterLink * link;
  // 当是从节点的情况下，指向主节点
  clusterNode * slaveof;
  // 是主节点
  int numslaves;
  clusterNode ** slaves;
  // 下线报告
  list * fail_reports;
  ...
}
```

**`clusterLink`**

这个结构保存了连接节点所需的比如套接字描述符，输入缓冲区和输出缓冲区以及与这个节点相关联的节点。

> `clusterLink`中保存的输入缓冲区和输出缓冲区是用于连接节点的，不同于`redisClient`中的是用于连接客户端的。

**`clusterState`**

除了上面两个数据结构，每个节点还保存了`clusterState`，即在当前节点的视角下，集群目前所处的状态：

```C 
struct clusterState{
  // 指向自己
  clusterNode * myself;
  // 集群节点名单，键为节点名字，值为节点对应的clusterNode结构
  dict *nodes;
  // 记录所有槽的指派信息
  clusterNode * slots[16384];
  // 槽和键之间的关系
  zskiplist * slot_to_keys;
  // 当前节点正在从其他节点导入的槽
  clusterNode * importing_slots_from[16384];
  // 当前节点正在迁移至其他节点的槽
  clusterNode * migrating_slots_to[16384];
  ...
}
```



节点之间通过发送`CLUSTER MEET`命令，将另一个节点(`B`)加入至当前节点(`A`)所在的集群里。`A`与`B`之间会互相为对方建立一个`clusterNode`结构，之后`A`通过`Gossip`协议将节点`B`的信息传播给其他节点，让其他节点也与`B`进行握手，最后被所有节点认识。

### 槽指派

集群的整个数据库被分为`16384`个槽(`slot`)，数据库中的每个键都属于这个槽中的一个，每个节点可以处理`0~16384`个槽。**当数据库中有任何一个槽没有得到处理，那么集群处于`fail`(下线)状态**。

每个节点的`slot`属性是一个二进制位数组，总共`2048`个字节，可以根据每一个位上的二进制值来判断节点是否负责处理该槽(复杂度为`o(1)`)。`numslots`负责记录节点处理的槽的数量，即值为`1`的二进制位数量。

一个节点除了会将自己负责的槽节点记录下来，还会通过消息发送给集群中的其他节点，以此来告知其他节点自己负责处理哪些槽。其他节点会在自己的`nodes`字典中查找该节点对应的`clusterNode`结构，对其中的`slots`进行保存更新。

由此可见，`clusterNode`中记录了当前节点处理的槽，而`clusterState`记录了所有槽分别被哪些节点处理，需要同时保存的原因在于：

- 如果只有节点记录了自身处理的槽，当查询某个槽是否被指派或者指派给了所有节点，就需要遍历所有的`clusterNode`的`slots`数组
- 如果程序需要将某个节点负责的槽信息发送给其他节点时(集群中的每个节点都会将自己的`slots`数组发送给集群中的其他节点)，只需要发送对应节点的`clusterNode.slots`，否则就需要遍历`clusterState.slots`，再记录下该节点负责的槽

因此，当执行`CLUSTER ADDSLOTS`命令时，首先会将`clusterState.slots`中对应的槽指向当前节点的`clusterNode`结构(如果发现已经指派，则返回错误)，然后将`clusterNode.slots`中对应的槽位置为`1`。

### 处理命令

当客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出命令要处理的数据库键属于哪个槽，并且检查是否指派给了自己(`clusterNode.slots[i]`是否指向自己)，如果属于当前节点，直接处理；否则节点会向客户端返回一个`MOVED`错误(不可见，单机会报错)，指引客户端转向正确节点。

> 节点和单机服务器的区别在于，节点只能使用`0`号数据库。

节点还使用了跳跃表(`slots_to_keys`)保存槽与键之间的关系，每个节点的分值都是一个槽号，每个节点的成员都是数据库键(同一分值下，按成员字典序排序)。通过这个跳跃表，节点可以方便地对属于某个或者某些槽的所有数据库键进行批量操作。

### 重新分片

是指将已经指派给某个节点的槽改派给另一个节点，并且将所属的键值对从源节点移动至目标节点，可以在线进行。它由`redis-trib`负责，进行原子地迁移:

- `SETSLOT <i> IMPORTING <source_id>`：向目标节点发送命令，将其`clusterState.importing_slots_from[i]`的值设置为`source id`所代表节点的`clusterNode`结构。
- `SETSLOG <i> MIGRATING <target_id>`：向源节点发送命令，将其`clusterState.migrating_slots_to[i]`的值设置为`target id`所代表节点的`clusterNode`结构。
- `GETKEYSINSLOT`
- `MIGRATE`
- `SETSLOT NODE`

需要注意的是，当在迁移的过程中，槽的一部分键值保存在源节点中，另一部分保存在目标节点中时，如果需要处理的数据库键下号属于正在被迁移的槽时：

1. 首先在自己数据库里查找指定的键，如果找到了则进行处理
2. 如果没有找到(查询`migrating_slots_to[i]`)，有可能已经被迁移，源节点将返回一个`ASK`错误(不可见)，指引客户端转向目标节点。之后客户端会先发送一个`ASKING`命令(打开自身的`REDIS_ASKING`标识，否则会被拒绝)，再重新发送本来想要执行的命令

> `REDIS_ASKING`是一个一次性标识。

### 复制与故障转移

集群中的主节点用于处理槽，从节点则用于复制某个主节点，在被复制的主节点下线时，代替主节点处理命令请求。

**复制**：

从节点会在自己的`clusterState.nodes`字典中找到主节点对应的`clusterNode`结构，并且将自己的`slaveof`指向该结构，修改自身的`flags`。集群中的所有节点都会在自身存储的代表主节点的`clusterNode`结构的`slave`属性和`numslaves`属性中记录正在复制这个主节点的从节点名单。

**故障转移**：

集群中的每个节点会定期向集群中的其他节点发送`PING`消息，以此检测对方是否在线。如果指定时间内，没有返回`PONG`，则源节点会将此节点标记为`疑似下线`。当主节点`A`得知主节点`B`认为主节点`C`疑似下线，`A`会在自身存储的`C`的`clusterNode`结构中为其添加`B`对其的下线报告。

如果在一个集群中，半数以上的主节点都将某个主节点`X`标记为疑似下线，那么这个主节点`X`将会被标记为已下线，将它标记为下线的主节点会向集群广播主节点`X`已下线的消息，所有收到这条消息的节点都会将其标记为下线。

当从节点发现自己的主节点下线后，会选举一个新的主节点，将原先主节点负责处理的槽全部指派给自己，并且告知整个集群自己已经变成新的主节点。

> 选举的过程大概如下：在每一个配置纪元里，从节点会向所有负责处理槽的主节点发送投票请求，要求对方将票投给自己(仍然是采取先来先到的原则)。当一个从节点获得超过`N/2+1`张选票时(具有投票权的主节点个数为`N`)，这个从节点就当选成为新的主节点。如果当前配置纪元没有选出节点，则会进入新的配置纪元直到选举完成。

### 消息

基本的消息结构为：

```C 
union clusterMsgData{
  // Gossip消息的正文
  struct {...} ping;
  struct {...} fail;
  struct {...} publish;
}
```



节点之间相互发送的消息有五种：

- `MEET`：发送者邀请接收者加入发送者所在的集群
- `PING`：每隔`1s`会从已知节点列表中随机选出`5`个节点，检测其中最长时间没有发送`PING`消息的节点是否在线(这样可以防止过久时间没有与该节点沟通)
- `PONG`：作为对`MEET`或者`PING`的回复，也可以让整个集群中的其他节点刷新此节点的认识
- `FAIL`：主节点`A`判断主节点`B`已经下线时，会向集群广播此节点的`FAIL`消息
- `PUBLISH`：节点收到此命令会向集群广播，所有接收到的节点都会执行相同的命令

> 节点发送的所有消息都由消息头包裹，包含自身的一些信息，可以用以消息接收者对自己所记录的消息发送者的相关属性进行更新。

`Gossip`协议由前三种消息实现，它们使用同样的消息正文，接收节点根据`type`来判断具体是哪一种消息。每次发送时，发送者都从自己的已知节点中随机选出两个节点，将其消息包含在消息正文中的`Gossip`消息结构(`clusterMsgDataGossip`)中，接收者根据对这两个节点的认知程度选择进行握手或者更新。

显然，当集群节点数量比较大的情况下，单纯使用`Gossip`协议，传播信息会带来一定延迟。而`FAIL`消息需要尽快地告知所有节点，因此`FAIL`节点中只需要保存下线节点的名字，告知接收者该节点已经下线。

当某个节点收到客户端发来的`PUBLISH <channel> <message>`时，它不仅会向`channel`发送`message`，同时还会向集群广播`PUBLISH`消息，最终实现所有节点都向`channel`发送`message`。

## 第十八章 发布与订阅

发布订阅功能包括`PUBLISH`/`SUBSCRIBE`/`PSUBSCRIBE`等组成。

### 订阅/退订频道

`redis`将频道订阅关系保存在`pubsub_channels`里，它是一个字典：

```C 
struct redisServer{
  dict * pubsub_channels;
}
```

其中，字典的键值代表某个订阅的频道，键的值是一个链表，代表订阅这个频道的所有客户端。

当用户执行`SUBSCRIBE`时，会有两种情况：

- 频道已经有订阅者，那么客户端添加至链表的尾部
- 如果没有订阅者，在字典中创建一个新的键，并且将客户端添加至链表中成为第一个元素

退订`UNSUBSCRIBE`与订阅正好相反，如果当删除客户端后链表变为空链表，那么也会在字典中删除这个频道。

### 订阅/退订模式

`redis`将模式订阅关系保存在`pubsub_patterns`里，它是一个链表：

```C 
struct redisServer{
  list * pubsub_patterns;
}
```

链表中的每一个节点都包含了一个`pubsubPattern`结构，记录了被订阅的模式，以及订阅模式的客户端。

当用户执行`PSUBSCRIBE`时，会有两个步骤：

1. 新建一个`pubsubPattern`结构，记录被订阅的模式以及订阅客户端

2. 将新建的结构添加至`pubsub_patterns`的表尾

> 也是就是，如果有订阅模式已经存在，也仍然会新建一个新的`pubsubPattern`节点。

当用户执行`PUNSUBSCRIBE`退订模式时，会在链表中寻找订阅模式与客户端都匹配的节点，将其删除。

### `PUBLISH`

当用户执行发布`PUBLISH <channel> <message>`时，会分为两个步骤：

1. 在`pubsub_channels`中寻找到`channel`，遍历其订阅者名单，然后将`message`发送给`channel`频道的订阅者

2. 遍历整个`pubsub_patterns`链表，查找与`channel`频道相匹配的模式，并将消息发送给订阅了这些模式的客户端

于是`PUBLISH`可以表示为：

```python
def publish(channel, message):
  channel_publish()
  pattern_publish()
```

### 查看订阅信息(`PUBSUB`)

**`PUBSUB CHANNELS [pattern]`**

- 如果不给定`pattern`参数，返回服务器当前被订阅的所有频道
- 如果给定`pattern`参数，返回服务器当前订阅频道中与其相匹配的频道

它是通过遍历`pubsub_channels`的所有键，并返回符合条件的键来实现的。

**`PUBSUB NUMSUB`**

接收任意多个频道作为输入参数，返回频道的订阅者数量。它是通过在`pubsub_channels`中找到对应频道的订阅者链表，并且返回链表长度来实现的。

**`PUBSUB NUMPAT`**

这个命令与订阅模式相关，返回当前被订阅模式的数量。是通过返回`pubsub_patterns`链表的长度来实现的。由于可能会有重复的模式订阅，因此这个命令返回参与了模式订阅的客户端之和，而不是总共有多少种模式订阅。

